\documentclass[11pt, a4paper]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{IEEEtrantools}
\usepackage{CJKutf8}
\usepackage{geometry}
\geometry{margin = 1cm}
\usepackage{enumitem}

\title{Mathematical Statitstics Homework 1}
\author{107305008}
\date{}

\begin{document}
\maketitle
\section{Maximum Likelihood Estimation 6.1}
\begin{description}
	\item[Problem 1.4.]\ 
	\begin{enumerate}[label=(\alph*)]
		\item given the pdf 
		\begin{equation*}
		f(x;\theta) = 
		\begin{cases}
		\frac{2x}{\theta^2} & \text{if } 0<x\leq\theta\\
		0 & \text{otherwise}
		\end{cases}
		\end{equation*}
		\begin{IEEEeqnarray*}{rCl}
			L(\theta) &=& \prod^n_{i=1}\frac{2x_i}{\theta^2}\\
			&=&\left(\frac{2}{\theta^2}\right)^n\prod^n_{i=1}x_i\\
			&=&\left(\frac{2}{\theta^2}\right)^n\prod^n_{i=1}x_iI(X_{(n)},\infty)
		\end{IEEEeqnarray*}
		for $L(\theta)$ to be maximized, \\$\hat{\theta}$=max($X_1,X_2\ldots, X_n$)
		\item
		let $Y = \text{max}(X_1, X_2\ldots,X_n)$, the CDF of Y
		\begin{IEEEeqnarray*}{rCrCl}
			F_Y(x)&=&P(Y\leq x) &=& P(X_1\leq x, X_2 \leq x \ldots X_n \leq x)\\
			&&&=& P(X \leq x)^n\\
			&&&=&\left(\int^x_0 \frac{2x}{\theta^2}\text{d}x\right)^n\\
			&&&=&\left(\frac{1}{\theta^2}x^2\big|^x_0\right)^n\\
			&&&=&\left(\frac{x}{\theta}\right)^{2n}
		\end{IEEEeqnarray*}
		the pdf of Y is thus
		\begin{IEEEeqnarray*}{rCl}
			f_Y(x) &=& \frac{\text{d}F(x)}{\text{d}x}\\
			&=& 2n\left(\frac{x}{\theta}\right)^{2n-1}\left(\frac{1}{\theta}\right)\\
		\end{IEEEeqnarray*}
		the expected value of $Y$ is,
		\begin{IEEEeqnarray*}{rCl}
		E(Y)&=&\int^\theta_0xf_Y(x)\text{d}x\\
		&=&\int^\theta_0x2n\left(\frac{x}{\theta}\right)^{2n-1}\left(\frac{1}{\theta}\right)\text{d}x\\
		&=&\frac{2n}{\theta^{2n}}\int^\theta_0x^{2n}\text{d}x\\
		&=&\frac{2n}{\theta^{2n}}\frac{1}{2n+1}x^{2n+1}\big|^\theta_0\\
		&=&\frac{2n}{2n+1}\theta
		\end{IEEEeqnarray*}
		thus, for $E(c\cdot\hat{\theta})=\theta$, $c = \frac{2n+1}{2n}$ 
		\newpage
		
		\item 
		let $y$ be the median of $f(x;\theta)$, thus it follows that the MLE of median is 	
		\begin{IEEEeqnarray*}{rClCl}
		F(y)&=&\int^y_0\frac{2x}{\hat{\theta}^2}\text{d}x&&\\
		&=&\frac{2}{\hat{\theta}^2}\int^y_0x\ \text{d}x&&\\
		&=&\frac{2}{\hat{\theta}^2}\frac{x^2}{2}\big|^y_0\\
		&=&\frac{2}{\hat{\theta}^2}\frac{y^2}{2}=\frac{y^2}{\hat{\theta}^2}&=&0.5\\
		y &=& \sqrt{\frac{1}{2}}\hat{\theta}&&
		\end{IEEEeqnarray*}
		thus the MLE of median is $\sqrt{\frac{1}{2}}\text{max}({X_1,X_2,\ldots,X_n})$
	\end{enumerate}
	
	
	\item[Problem 1.5.]\ \\
		the likelihood function of $f(\vec{x};\theta)$ is
		\begin{IEEEeqnarray*}{rCl}
			L(\theta) &=& \prod^n_{i=1}1/\theta e^{-x_i/\theta} \\
			&=&\theta^{-n}e^{-1/\theta{\sum_{i=1}^nx_i}}
		\end{IEEEeqnarray*}
		and thus, the log likelihood of which is
		\begin{equation*}
			l(\theta) = -ln\theta + -1/\theta\sum^n_{i=1}x_i
		\end{equation*}
		and by taking the derivative of log likelihood function
		\begin{equation*}
		l'(\theta) = \frac{-n}{\theta}+ \frac{1}{\theta^2}\sum^n_{i=1}x_i
		\end{equation*}
		when the equation equals to zero, it follows that,
		\begin{IEEEeqnarray*}{rCl}
			0 &=& \frac{-n}{\theta}+ \frac{1}{\theta^2}\sum^n_{i=1}x_i\\
			0 &=& \frac{-n\theta + \sum^n_{i=1}x_i}{\theta^2}\\
			n\theta &=& \sum^n_{i=1}x_i\\
			\hat{\theta} &=& \frac{1}{n}\sum^n_{i=1}x_i\\
			&=&\bar{x}
		\end{IEEEeqnarray*}
		taking the second derivative of $l(\theta)$
		\begin{IEEEeqnarray*}{rCl}
			l''(\theta) &=& \frac{n}{\theta^2}- \frac{2}{\theta^3}\sum^n_{i=1}x_i\\
			&=& \frac{n\theta-2\sum^n_{i=1}x_i}{\theta^3}
		\end{IEEEeqnarray*}
		and plugging in $\theta=\hat{\theta}=\bar{x}$\\
		thus $\bar{x}$ is the the MLE for $f(x;\theta)$
		\begin{IEEEeqnarray*}{rCl}
			l''(\bar{x}) &=& \frac{n\bar{x}-2\sum^n_{i=1}x_i}{\bar{x}^3}\\
			&=& \frac{n\bar{x}-2n\bar{x}}{\bar{x}^3},\qquad \text{which is smaller than 0}
		\end{IEEEeqnarray*}
		thus the MLE for $P(X\leq2)$ is by plugging $\theta = \bar{x}$ into the integration,
		\begin{IEEEeqnarray*}{rCl}
		P(X \leq 2 ; \bar{x}) &=& \int^2_0f(x;\bar{x})dx \\
		&=& \int^2_0\bar{x} e^{-x/\bar{x}}dx\\
		&=& \frac{-\bar{x}}{\bar{x}}e^{-x/\bar{x}}\big| ^2_0\\
		&=& 1 - e^{-2/\bar{x}}
		\end{IEEEeqnarray*}
		thus the MLE for $P(X\leq2)$ is $1 - e^{-2/\bar{x}}$
		
		
		
		
		
	\item[Problem 1.11.]\ \\
	let r.v. $X$ follow a Poisson distribution, which means,
	\begin{equation*}
		P(X) = \frac{\lambda^xe^{-\lambda}}{x!} \qquad \text{where }x=0,1,2\ldots,\quad m>0
	\end{equation*}
	the likelihood function has a form of 
	\begin{IEEEeqnarray*}{rCl}
		L(\theta) &=& \prod^n_{i=1} \frac{\theta^{x_i}e^{-\theta}}{x_i!}\\
		&=& \frac{\theta^{\sum^n_{i=1}x_i}e^{-n\theta}}{\prod^n_{i=1}x_i!}
	\end{IEEEeqnarray*}
	the log likelihood function thus looks like
	\begin{IEEEeqnarray*}{rCl}
		l(\theta) &=& (\sum^n_{i=1}x_i) ln\theta + -n\theta -\sum^n_{i=1}lnx_i
	\end{IEEEeqnarray*}
	taking the derivative with respect to $\theta$
	\begin{IEEEeqnarray*}{rCl}
		l'(\theta) &=& \frac{1}{\theta}\sum^n_{i=1}x_i -n \label{eq:1}
	\end{IEEEeqnarray*}
	when $l'(\theta) = 0$
	\begin{IEEEeqnarray*}{lCl}
		0 &=& \frac{1}{\theta}\sum^n_{i=1}x_i -n \\
		n\theta &=& \sum^n_{i=1}x_i\\
		\hat{\theta} &=& \frac{1}{n}\sum^n_{i=1}x_i	\\
		&=& \bar{x}	
	\end{IEEEeqnarray*}
	taking the double derivative of $l(\theta)$
	thus the MLE of the $\theta$ is $\bar{x}$
	\begin{IEEEeqnarray*}{rCl}
		l''(\theta) &=& \frac{-1}{\theta^2}\sum^n_{i=1}x_i
	\end{IEEEeqnarray*}
	which is less than zero, for all values of $\theta$, thus $\hat{\theta}$ is a maximum point.\\
	since $0 <\theta \leq 2$,\\ 
	if $\bar{x}>2$, then 2 is the MLE\\
	if $\bar{x}<2$, then $\bar{x}$ is the MLE,\\
	thus the MLE of $\theta$ is $\text{min}\{\bar{x},2\}$
\end{description}


\end{document}

















